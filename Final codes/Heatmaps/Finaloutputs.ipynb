{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFODE0u1j2Hc",
        "outputId": "94ccf3de-8259-4a4e-dce1-0c6562f2d75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing: tracking2 ===\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# AFL Heatmap Batch Exporter (dual-schema, Colab-ready)\n",
        "# ===========================================\n",
        "# Description:\n",
        "#   This script generates AFL field heatmaps from tracking/event CSV data.\n",
        "#   It supports two different CSV schemas (comma- or pipe-delimited) and\n",
        "#   unifies them into one standard format.\n",
        "#\n",
        "# Outputs:\n",
        "#   - Overall heatmap for each dataset\n",
        "#   - Per-player (or per-track ID) heatmaps\n",
        "#   - Zone-based heatmaps (Back 50, Midfield, Forward 50)\n",
        "#\n",
        "# Important details:\n",
        "#   - AFL ground size: 159.5 m length × 128.8 m width\n",
        "#   - Heatmap resolution: 200 (X) × 150 (Y) grid cells\n",
        "#   - Gaussian blur applied with sigma = 2.0\n",
        "#   - Zones split using circular arcs at 50 m from each goal\n",
        "#\n",
        "# Requirements:\n",
        "#   pip install numpy pandas matplotlib scipy\n",
        "# ===========================================\n",
        "\n",
        "import os\n",
        "import io\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import Normalize\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# -------------------------\n",
        "# Config\n",
        "# -------------------------\n",
        "FIELD_LENGTH_M = 159.5   # AFL field length in metres\n",
        "FIELD_WIDTH_M  = 128.8   # AFL field width in metres\n",
        "a = FIELD_LENGTH_M / 2.0 # semi-major axis (x direction)\n",
        "b = FIELD_WIDTH_M  / 2.0 # semi-minor axis (y direction)\n",
        "\n",
        "NX, NY = 200, 150        # grid resolution (X × Y cells)\n",
        "SIGMA  = 2.0             # blur amount for smoother heatmaps\n",
        "\n",
        "# Input CSV files (path, label)\n",
        "INPUTS = [\n",
        "    (\"Video_tracking.csv\", \"tracking2\"),\n",
        "]\n",
        "\n",
        "OUT_ROOT = \"outputs\"     # output directory\n",
        "\n",
        "# Weight columns (confidence values)\n",
        "WEIGHT_COLS = [\"confidence\", \"conf\"]\n",
        "\n",
        "# Standard set of columns expected in unified data\n",
        "UNIFIED_COLS = [\n",
        "    \"frame_id\",\"player_id\",\"timestamp_s\",\n",
        "    \"x1\",\"y1\",\"x2\",\"y2\",\"cx\",\"cy\",\"w\",\"h\",\n",
        "    \"confidence\",\"class_id\",\"visibility\"\n",
        "]\n",
        "\n",
        "# -------------------------\n",
        "# Helpers: mapping & grid\n",
        "# -------------------------\n",
        "def raw_bbox(xs, ys, pad_ratio=0.02):\n",
        "    \"\"\"Get bounding box for raw coordinates with small padding.\"\"\"\n",
        "    xmin, xmax = float(np.min(xs)), float(np.max(xs))\n",
        "    ymin, ymax = float(np.min(ys)), float(np.max(ys))\n",
        "    dx, dy = max(xmax - xmin, 1e-9), max(ymax - ymin, 1e-9)\n",
        "    return (xmin - dx*pad_ratio, xmax + dx*pad_ratio,\n",
        "            ymin - dy*pad_ratio, ymax + dy*pad_ratio)\n",
        "\n",
        "def raw_to_metres(x, y, bbox_raw, a, b):\n",
        "    \"\"\"Convert raw coordinates to metre coordinates scaled to AFL oval.\"\"\"\n",
        "    xmin, xmax, ymin, ymax = bbox_raw\n",
        "    x_m = ((x - xmin) / max(1e-9, (xmax - xmin))) * (2*a) - a\n",
        "    y_m = ((y - ymin) / max(1e-9, (ymax - ymin))) * (2*b) - b\n",
        "    return x_m, y_m\n",
        "\n",
        "def make_oval_mask_metres(nx, ny, a, b):\n",
        "    \"\"\"Create grid mask to keep values inside AFL oval shape.\"\"\"\n",
        "    x_edges = np.linspace(-a, a, nx + 1)\n",
        "    y_edges = np.linspace(-b, b, ny + 1)\n",
        "    xc = (x_edges[:-1] + x_edges[1:]) / 2\n",
        "    yc = (y_edges[:-1] + y_edges[1:]) / 2\n",
        "    Xc, Yc = np.meshgrid(xc, yc, indexing=\"xy\")\n",
        "    mask = (Xc**2)/(a**2) + (Yc**2)/(b**2) <= 1.0\n",
        "    return x_edges, y_edges, mask\n",
        "\n",
        "def heatmap_from_metres(x_m, y_m, a, b, nx=NX, ny=NY, sigma=SIGMA, weights=None):\n",
        "    \"\"\"Make 2D heatmap grid from metre coords, apply blur, mask outside oval.\"\"\"\n",
        "    x_edges, y_edges, mask = make_oval_mask_metres(nx, ny, a, b)\n",
        "    H, _, _ = np.histogram2d(x_m, y_m, bins=[x_edges, y_edges], weights=weights)\n",
        "    H = H.T\n",
        "    if sigma and sigma > 0:\n",
        "        H = gaussian_filter(H, sigma=sigma)\n",
        "    H = np.where(mask, H, np.nan)\n",
        "    return H, x_edges, y_edges\n",
        "\n",
        "# -------------------------\n",
        "# Field drawing\n",
        "# -------------------------\n",
        "def draw_afl_field(ax, a, b,\n",
        "                   centre_square=50.0,\n",
        "                   centre_inner_d=3.0,\n",
        "                   centre_outer_d=10.0,\n",
        "                   goal_square_depth=9.0,\n",
        "                   goal_square_width=6.4,\n",
        "                   arc_r=50.0,\n",
        "                   line_color=\"white\", lw=2.0, alpha=0.95):\n",
        "    \"\"\"Draw AFL oval boundary and main field features.\"\"\"\n",
        "    t = np.linspace(0, 2*np.pi, 800)\n",
        "    ax.plot(a*np.cos(t), b*np.sin(t), color=line_color, lw=lw, alpha=alpha) # oval boundary\n",
        "    ax.plot([0, 0], [-b, b], color=line_color, lw=lw, alpha=alpha*0.9)     # centre line\n",
        "    # (rest: centre square, circles, arcs, goal squares)\n",
        "\n",
        "# -------------------------\n",
        "# Plot helper\n",
        "# -------------------------\n",
        "def plot_heatmap(H, x_edges, y_edges, a, b, out_path, alpha_img=0.9):\n",
        "    \"\"\"Plot heatmap on AFL oval background and save as PNG.\"\"\"\n",
        "    title = os.path.splitext(os.path.basename(out_path))[0]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(11, 8))\n",
        "    # draw green oval background\n",
        "    t = np.linspace(0, 2*np.pi, 600)\n",
        "    ax.fill(a*np.cos(t), b*np.sin(t), color=(0.05, 0.35, 0.05), alpha=1.0, zorder=0)\n",
        "    ax.set_xlim([-a, a]); ax.set_ylim([-b, b])\n",
        "    ax.set_aspect(\"equal\"); ax.set_axis_off()\n",
        "\n",
        "    # set heatmap scale\n",
        "    finite_vals = H[np.isfinite(H)]\n",
        "    vmin = 0.0\n",
        "    vmax = (np.nanpercentile(finite_vals, 99) if finite_vals.size else 1.0)\n",
        "\n",
        "    extent = [x_edges.min(), x_edges.max(), y_edges.min(), y_edges.max()]\n",
        "    im = ax.imshow(H, origin=\"lower\", extent=extent, aspect=\"equal\",\n",
        "                   interpolation=\"bilinear\", cmap=\"viridis\",\n",
        "                   norm=Normalize(vmin=vmin, vmax=vmax, clip=True),\n",
        "                   alpha=alpha_img, zorder=2)\n",
        "\n",
        "    # draw field lines\n",
        "    draw_afl_field(ax, a, b)\n",
        "\n",
        "    # add scale bar\n",
        "    sb_y = -b + 8\n",
        "    sb_x0, sb_x1 = -a + 12, -a + 32\n",
        "    ax.plot([sb_x0, sb_x1], [sb_y, sb_y], color=\"white\", lw=4, alpha=0.95)\n",
        "    ax.text((sb_x0 + sb_x1)/2, sb_y - 4, \"20 m\", ha=\"center\", va=\"top\",\n",
        "            color=\"white\", fontsize=11)\n",
        "\n",
        "    # title + colorbar\n",
        "    ax.set_title(title, color=\"white\")\n",
        "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    cbar.set_label(\"Intensity\")\n",
        "\n",
        "    # save figure\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "    fig.savefig(out_path, dpi=220)\n",
        "    plt.close(fig)\n",
        "\n",
        "# -------------------------\n",
        "# Zones (circular 50 m arcs)\n",
        "# -------------------------\n",
        "def split_zones_circular(df_m):\n",
        "    \"\"\"Split dataframe into Back 50, Midfield, and Forward 50 zones.\"\"\"\n",
        "    dist_left  = np.sqrt((df_m[\"x_m\"] + a)**2 + (df_m[\"y_m\"])**2)\n",
        "    dist_right = np.sqrt((df_m[\"x_m\"] - a)**2 + (df_m[\"y_m\"])**2)\n",
        "    back50     = df_m[dist_left  <= 50].copy()\n",
        "    fwd50      = df_m[dist_right <= 50].copy()\n",
        "    mid        = df_m[(dist_left > 50) & (dist_right > 50)].copy()\n",
        "    return {\"Back 50\": back50, \"Midfield\": mid, \"Forward 50\": fwd50}\n",
        "\n",
        "# -------------------------\n",
        "# CSV loader (handles both schemas)\n",
        "# -------------------------\n",
        "XUAN_REQUIRED = [ \"frame_id\",\"player_id\",\"timestamp_s\",\"x1\",\"y1\",\"x2\",\"y2\",\"cx\",\"cy\",\"w\",\"h\",\"confidence\" ]\n",
        "PIPE_REQUIRED = [ \"frame_id\",\"track_id\",\"x\",\"y\",\"width\",\"height\",\"conf\",\"class_id\",\"visibility\" ]\n",
        "\n",
        "def _coerce_numeric(df, cols):\n",
        "    \"\"\"Convert given columns to numeric if possible.\"\"\"\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def _read_with_possible_pipe(path):\n",
        "    \"\"\"Detect delimiter (comma or pipe) and read CSV.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        head = f.read(4096)\n",
        "    sep = \"|\" if (\"|\" in head and \",\" not in head.splitlines()[0]) else \",\"\n",
        "    try:\n",
        "        df = pd.read_csv(path, sep=sep)\n",
        "    except Exception:\n",
        "        df = pd.read_csv(path, sep=sep, header=None)\n",
        "    return df, sep\n",
        "\n",
        "def _assign_if_headerless(df, expected_cols):\n",
        "    \"\"\"Assign headers if missing and column count matches expected.\"\"\"\n",
        "    if set(expected_cols).issubset(df.columns):\n",
        "        return df\n",
        "    if df.shape[1] >= len(expected_cols):\n",
        "        df2 = df.iloc[:, :len(expected_cols)].copy()\n",
        "        df2.columns = expected_cols\n",
        "        return df2\n",
        "    return df\n",
        "\n",
        "def _to_unified_columns(df):\n",
        "    \"\"\"Convert dataframe to unified column schema.\"\"\"\n",
        "    cols = df.columns.tolist()\n",
        "    out = df.copy()\n",
        "\n",
        "    # Map player_id if missing\n",
        "    if \"player_id\" not in out.columns:\n",
        "        if \"track_id\" in out.columns:\n",
        "            out[\"player_id\"] = out[\"track_id\"]\n",
        "        else:\n",
        "            out[\"player_id\"] = np.nan\n",
        "\n",
        "    # Compute centres if not present\n",
        "    if \"cx\" not in out.columns and all(c in out.columns for c in [\"x\",\"y\",\"width\",\"height\"]):\n",
        "        out[\"cx\"] = pd.to_numeric(out[\"x\"], errors=\"coerce\") + pd.to_numeric(out[\"width\"], errors=\"coerce\")/2.0\n",
        "        out[\"cy\"] = pd.to_numeric(out[\"y\"], errors=\"coerce\") + pd.to_numeric(out[\"height\"], errors=\"coerce\")/2.0\n",
        "\n",
        "    # Map confidence if only \"conf\"\n",
        "    if \"confidence\" not in out.columns and \"conf\" in out.columns:\n",
        "        out[\"confidence\"] = out[\"conf\"]\n",
        "\n",
        "    # Ensure all unified columns exist\n",
        "    for c in UNIFIED_COLS:\n",
        "        if c not in out.columns:\n",
        "            out[c] = np.nan\n",
        "\n",
        "    # Convert to numeric\n",
        "    out = _coerce_numeric(out, UNIFIED_COLS)\n",
        "\n",
        "    # Drop rows without centres\n",
        "    out = out.dropna(subset=[\"cx\",\"cy\"])\n",
        "    out = out[np.isfinite(out[\"cx\"]) & np.isfinite(out[\"cy\"])]\n",
        "    return out.reset_index(drop=True)\n",
        "\n",
        "def load_events_csv_any(path: str) -> pd.DataFrame:\n",
        "    \"\"\"Robust loader that handles both CSV schemas (comma and pipe).\"\"\"\n",
        "    df, sep = _read_with_possible_pipe(path)\n",
        "    uni = _to_unified_columns(df)\n",
        "    if not uni.empty:\n",
        "        return uni\n",
        "    # Try headerless fallback attempts\n",
        "    if sep == \",\":\n",
        "        df_hless = pd.read_csv(path, sep=sep, header=None)\n",
        "        df_hless = _assign_if_headerless(df_hless, XUAN_REQUIRED)\n",
        "        uni = _to_unified_columns(df_hless)\n",
        "        if not uni.empty:\n",
        "            return uni\n",
        "    if sep == \"|\":\n",
        "        df_hless = pd.read_csv(path, sep=sep, header=None)\n",
        "        df_hless = _assign_if_headerless(df_hless, PIPE_REQUIRED)\n",
        "        uni = _to_unified_columns(df_hless)\n",
        "        if not uni.empty:\n",
        "            return uni\n",
        "    # Last brute-force attempt\n",
        "    df_hless = pd.read_csv(path, sep=sep, header=None)\n",
        "    if df_hless.shape[1] >= 9:\n",
        "        tmp = df_hless.iloc[:, :len(PIPE_REQUIRED)].copy()\n",
        "        tmp.columns = PIPE_REQUIRED\n",
        "        uni = _to_unified_columns(tmp)\n",
        "        if not uni.empty:\n",
        "            return uni\n",
        "    raise ValueError(f\"{os.path.basename(path)}: could not parse CSV (sep='{sep}')\")\n",
        "\n",
        "# -------------------------\n",
        "# Weight selection\n",
        "# -------------------------\n",
        "def choose_weights_unified(df):\n",
        "    \"\"\"Select weight column if available (confidence/conf).\"\"\"\n",
        "    for c in WEIGHT_COLS:\n",
        "        if c in df.columns:\n",
        "            return pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0).to_numpy(dtype=float)\n",
        "    return None\n",
        "\n",
        "# -------------------------\n",
        "# Per-dataset pipeline\n",
        "# -------------------------\n",
        "def process_one_dataset(csv_path, label):\n",
        "    \"\"\"Process one dataset: load, convert, generate heatmaps.\"\"\"\n",
        "    print(f\"\\n=== Processing: {label} ===\")\n",
        "    out_base = os.path.join(OUT_ROOT, label)\n",
        "    out_overall = os.path.join(out_base, \"overall\")\n",
        "    out_perid   = os.path.join(out_base, \"per_id\")\n",
        "    out_zones   = os.path.join(out_base, \"zones\")\n",
        "    os.makedirs(out_overall, exist_ok=True)\n",
        "    os.makedirs(out_perid,   exist_ok=True)\n",
        "    os.makedirs(out_zones,   exist_ok=True)\n",
        "\n",
        "    # Load CSV into unified dataframe\n",
        "    df = load_events_csv_any(csv_path)\n",
        "    if df.empty:\n",
        "        print(f\"({label}) Empty after load; skipping.\")\n",
        "        return\n",
        "\n",
        "    # Convert raw coords → metres\n",
        "    bbox = raw_bbox(df[\"cx\"].values, df[\"cy\"].values)\n",
        "    df[\"x_m\"], df[\"y_m\"] = raw_to_metres(df[\"cx\"].values, df[\"cy\"].values, bbox, a, b)\n",
        "\n",
        "    # Select weights\n",
        "    weights = choose_weights_unified(df)\n",
        "\n",
        "    # A) Overall heatmap\n",
        "    H, xe, ye = heatmap_from_metres(df[\"x_m\"].values, df[\"y_m\"].values, a, b, NX, NY, SIGMA, weights)\n",
        "    plot_heatmap(H, xe, ye, a, b, out_path=os.path.join(out_overall, \"overall.png\"))\n",
        "\n",
        "    # B) Per-player heatmaps\n",
        "    id_series = df[\"player_id\"]\n",
        "    if id_series.notna().any():\n",
        "        for pid, sub in df.groupby(\"player_id\"):\n",
        "            if pd.isna(pid) or sub.empty:\n",
        "                continue\n",
        "            w = choose_weights_unified(sub)\n",
        "            H_i, xe_i, ye_i = heatmap_from_metres(sub[\"x_m\"].values, sub[\"y_m\"].values, a, b, NX, NY, SIGMA, w)\n",
        "            out_path = os.path.join(out_perid, f\"id_{int(pid) if float(pid).is_integer() else pid}.png\")\n",
        "            plot_heatmap(H_i, xe_i, ye_i, a, b, out_path=out_path)\n",
        "    else:\n",
        "        print(f\"({label}) No usable ID column; skipping per-id maps.\")\n",
        "\n",
        "    # C) Zone heatmaps\n",
        "    zones = split_zones_circular(df)\n",
        "    for zname, zdf in zones.items():\n",
        "        if zdf.empty:\n",
        "            print(f\"({label}) Zone empty: {zname}\")\n",
        "            continue\n",
        "        w = choose_weights_unified(zdf)\n",
        "        H_z, xe_z, ye_z = heatmap_from_metres(zdf[\"x_m\"].values, zdf[\"y_m\"].values, a, b, NX, NY, SIGMA, w)\n",
        "        fname = zname.lower().replace(\" \", \"_\") + \".png\"\n",
        "        plot_heatmap(H_z, xe_z, ye_z, a, b, out_path=os.path.join(out_zones, fname))\n",
        "\n",
        "# -------------------------\n",
        "# Run all datasets\n",
        "# -------------------------\n",
        "for path, label in INPUTS:\n",
        "    try:\n",
        "        process_one_dataset(path, label)\n",
        "    except Exception as e:\n",
        "        print(f\"!! Failed {label}: {e}\")\n",
        "\n",
        "print(f\"\\nDone. Outputs in: {os.path.abspath(OUT_ROOT)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# (Optional) ZIP everything for download in Colab\n",
        "# -------------------------\n",
        "import shutil\n",
        "from google.colab import files\n",
        "shutil.make_archive(\"all_heatmaps\", \"zip\", OUT_ROOT)\n",
        "files.download(\"all_heatmaps.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gT-AoYb-j7jn",
        "outputId": "5de2e671-bb4f-42b8-f406-8cc80cb4172a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ebc5a5a0-4a42-4618-ab92-e8ec31ad06c8\", \"all_heatmaps.zip\", 19548695)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8RYIdbvm3Vo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}